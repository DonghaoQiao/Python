{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "IMAGE_W = 600\n",
    "IMAGE_H = 600\n",
    "\n",
    "Ratio = None\n",
    "\n",
    "# The picture needed converting\n",
    "CONTENT_IMG = './images/Taipei101.jpg'\n",
    "\n",
    "# The style picture\n",
    "STYLE_IMG = './images/StarryNight.jpg'\n",
    "\n",
    "# The noise ratio, which is used to generate the initial picture\n",
    "INI_NOISE_RATIO = 0.7\n",
    "\n",
    "# The balance parameter, which is used to to balance the weights of style loss and content loss\n",
    "STYLE_STRENGTH = 500\n",
    "\n",
    "# How many iterations you want to run\n",
    "ITERATION = 2000\n",
    "\n",
    "# Which layers of the content network you want to use\n",
    "CONTENT_LAYERS = [('conv4_2',1.)]\n",
    "\n",
    "# Which layers of the style network you want to use\n",
    "STYLE_LAYERS = [('conv1_1',2.),('conv2_1',1.),('conv3_1',0.5),('conv4_1',0.25),('conv5_1',0.125)]\n",
    "\n",
    "# All the layers\n",
    "layers = ['conv1_1', 'conv1_2', 'conv2_1', 'conv2_2', 'conv3_1', 'conv3_2', 'conv3_3', 'conv3_4',\n",
    "          'conv4_1', 'conv4_2', 'conv4_3', 'conv4_4', 'conv5_1', 'conv5_2', 'conv5_3', 'conv5_4', ]\n",
    "\n",
    "\n",
    "def vgg19(input, model_path=None):\n",
    "    '''\n",
    "    Build the VGG19 network, which is initialized with the pre-trained VGG19 model.\n",
    "    :param input: The input image.\n",
    "    :param model_path:Which path the VGG19 model is stored.\n",
    "    :return:A python dict, which contains all the layers needed.\n",
    "    '''\n",
    "    if model_path is None:\n",
    "        model_path = 'vgg19.npy'\n",
    "\n",
    "    if os.path.isfile(model_path) is False:\n",
    "        raise FileNotFoundError('vgg19.npy cannot be found!!!')\n",
    "\n",
    "    wDict = np.load(model_path, encoding=\"bytes\").item()\n",
    "\n",
    "    net = {}\n",
    "    net['input'] = input\n",
    "\n",
    "    # conv1_1\n",
    "    weight1_1 = tf.Variable(wDict['conv1_1'][0], trainable=False)\n",
    "    bias1_1 = tf.Variable(wDict['conv1_1'][1], trainable=False)\n",
    "    net['conv1_1'] = tf.nn.relu(tf.nn.conv2d(net['input'], weight1_1, [1, 1, 1, 1], 'SAME') + bias1_1)\n",
    "\n",
    "    # conv1_2\n",
    "    weight1_2 = tf.Variable(wDict['conv1_2'][0], trainable=False)\n",
    "    bias1_2 = tf.Variable(wDict['conv1_2'][1], trainable=False)\n",
    "    net['conv1_2'] = tf.nn.relu(tf.nn.conv2d(net['conv1_1'], weight1_2, [1, 1, 1, 1], 'SAME') + bias1_2)\n",
    "\n",
    "    # pool1\n",
    "    net['pool1'] = tf.nn.avg_pool(net['conv1_2'], [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "    # conv2_1\n",
    "    weight2_1 = tf.Variable(wDict['conv2_1'][0], trainable=False)\n",
    "    bias2_1 = tf.Variable(wDict['conv2_2'][1], trainable=False)\n",
    "    net['conv2_1'] = tf.nn.relu(tf.nn.conv2d(net['pool1'], weight2_1, [1, 1, 1, 1], 'SAME') + bias2_1)\n",
    "\n",
    "    # conv2_2\n",
    "    weight2_2 = tf.Variable(wDict['conv2_2'][0], trainable=False)\n",
    "    bias2_2 = tf.Variable(wDict['conv2_2'][1], trainable=False)\n",
    "    net['conv2_2'] = tf.nn.relu(tf.nn.conv2d(net['conv2_1'], weight2_2, [1, 1, 1, 1], 'SAME') + bias2_2)\n",
    "\n",
    "    # pool2\n",
    "    net['pool2'] = tf.nn.avg_pool(net['conv2_2'], [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "    # conv3_1\n",
    "    weight3_1 = tf.Variable(wDict['conv3_1'][0], trainable=False)\n",
    "    bias3_1 = tf.Variable(wDict['conv3_1'][1], trainable=False)\n",
    "    net['conv3_1'] = tf.nn.relu(tf.nn.conv2d(net['pool2'], weight3_1, [1, 1, 1, 1], 'SAME') + bias3_1)\n",
    "\n",
    "    # conv3_2\n",
    "    weight3_2 = tf.Variable(wDict['conv3_2'][0], trainable=False)\n",
    "    bias3_2 = tf.Variable(wDict['conv3_2'][1], trainable=False)\n",
    "    net['conv3_2'] = tf.nn.relu(tf.nn.conv2d(net['conv3_1'], weight3_2, [1, 1, 1, 1], 'SAME') + bias3_2)\n",
    "\n",
    "    # conv3_3\n",
    "    weight3_3 = tf.Variable(wDict['conv3_3'][0], trainable=False)\n",
    "    bias3_3 = tf.Variable(wDict['conv3_3'][1], trainable=False)\n",
    "    net['conv3_3'] = tf.nn.relu(tf.nn.conv2d(net['conv3_2'], weight3_3, [1, 1, 1, 1], 'SAME') + bias3_3)\n",
    "\n",
    "    # conv3_4\n",
    "    weight3_4 = tf.Variable(wDict['conv3_4'][0], trainable=False)\n",
    "    bias3_4 = tf.Variable(wDict['conv3_4'][1], trainable=False)\n",
    "    net['conv3_4'] = tf.nn.relu(tf.nn.conv2d(net['conv3_3'], weight3_4, [1, 1, 1, 1], 'SAME') + bias3_4)\n",
    "\n",
    "    # pool3\n",
    "    net['pool3'] = tf.nn.avg_pool(net['conv3_4'], [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "    # conv4_1\n",
    "    weight4_1 = tf.Variable(wDict['conv4_1'][0], trainable=False)\n",
    "    bias4_1 = tf.Variable(wDict['conv4_1'][1], trainable=False)\n",
    "    net['conv4_1'] = tf.nn.relu(tf.nn.conv2d(net['pool3'], weight4_1, [1, 1, 1, 1], 'SAME') + bias4_1)\n",
    "\n",
    "    # conv4_2\n",
    "    weight4_2 = tf.Variable(wDict['conv4_2'][0], trainable=False)\n",
    "    bias4_2 = tf.Variable(wDict['conv4_2'][1], trainable=False)\n",
    "    net['conv4_2'] = tf.nn.relu(tf.nn.conv2d(net['conv4_1'], weight4_2, [1, 1, 1, 1], 'SAME') + bias4_2)\n",
    "\n",
    "    # conv4_3\n",
    "    weight4_3 = tf.Variable(wDict['conv4_3'][0], trainable=False)\n",
    "    bias4_3 = tf.Variable(wDict['conv4_3'][1], trainable=False)\n",
    "    net['conv4_3'] = tf.nn.relu(tf.nn.conv2d(net['conv4_2'], weight4_3, [1, 1, 1, 1], 'SAME') + bias4_3)\n",
    "\n",
    "    # conv4_4\n",
    "    weight4_4 = tf.Variable(wDict['conv4_4'][0], trainable=False)\n",
    "    bias4_4 = tf.Variable(wDict['conv4_4'][1], trainable=False)\n",
    "    net['conv4_4'] = tf.nn.relu(tf.nn.conv2d(net['conv4_3'], weight4_4, [1, 1, 1, 1], 'SAME') + bias4_4)\n",
    "\n",
    "    # pool4\n",
    "    net['pool4'] = tf.nn.avg_pool(net['conv4_4'], [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "    # conv5_1\n",
    "    weight5_1 = tf.Variable(wDict['conv5_1'][0], trainable=False)\n",
    "    bias5_1 = tf.Variable(wDict['conv5_1'][1], trainable=False)\n",
    "    net['conv5_1'] = tf.nn.relu(tf.nn.conv2d(net['pool4'], weight5_1, [1, 1, 1, 1], 'SAME') + bias5_1)\n",
    "\n",
    "    # conv5_2\n",
    "    weight5_2 = tf.Variable(wDict['conv5_2'][0], trainable=False)\n",
    "    bias5_2 = tf.Variable(wDict['conv5_2'][1], trainable=False)\n",
    "    net['conv5_2'] = tf.nn.relu(tf.nn.conv2d(net['conv5_1'], weight5_2, [1, 1, 1, 1], 'SAME') + bias5_2)\n",
    "\n",
    "    # conv5_3\n",
    "    weight5_3 = tf.Variable(wDict['conv5_3'][0], trainable=False)\n",
    "    bias5_3 = tf.Variable(wDict['conv5_3'][1], trainable=False)\n",
    "    net['conv5_3'] = tf.nn.relu(tf.nn.conv2d(net['conv5_2'], weight5_3, [1, 1, 1, 1], 'SAME') + bias5_3)\n",
    "\n",
    "    # conv5_4\n",
    "    weight5_4 = tf.Variable(wDict['conv5_4'][0], trainable=False)\n",
    "    bias5_4 = tf.Variable(wDict['conv5_4'][1], trainable=False)\n",
    "    net['conv5_4'] = tf.nn.relu(tf.nn.conv2d(net['conv5_3'], weight5_4, [1, 1, 1, 1], 'SAME') + bias5_4)\n",
    "\n",
    "    # pool5\n",
    "    net['pool5'] = tf.nn.avg_pool(net['conv5_4'], [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def gram_matrix(tensor, length, depth):\n",
    "    '''\n",
    "    :param tensor:The tensor you need to convert, which could be a numpy array or a TensorFlow tensor.\n",
    "    :param length:The length you need to convert to.\n",
    "    :param depth:The depth you need to convert to.\n",
    "    :return:A tensor.\n",
    "    '''\n",
    "    tensor = tf.reshape(tensor, (length, depth))\n",
    "    return tf.matmul(tf.transpose(tensor), tensor)\n",
    "    pass\n",
    "\n",
    "\n",
    "def build_content_loss(combination, content):\n",
    "    '''\n",
    "    :param combination:The network which is the combination of the style network and content network,\n",
    "                       that is the style-transfered network\n",
    "    :param content:The network of the content image\n",
    "    :return:The loss between the combination and the content\n",
    "    '''\n",
    "    content_sum = 0.0\n",
    "    for i, l in enumerate(CONTENT_LAYERS):\n",
    "        shape = combination[l[0]].get_shape()\n",
    "        M = shape[1].value * shape[2].value\n",
    "        N = shape[3].value\n",
    "        content_sum += l[1] * 0.25/(M ** 0.5 + N ** 0.5) * tf.reduce_sum(tf.pow(combination[l[0]] - content[l[0]], 2))\n",
    "    return content_sum\n",
    "    pass\n",
    "\n",
    "\n",
    "def build_style_loss(combination, style):\n",
    "    '''\n",
    "    :param combination: The network which is the combination of the style network and content network,\n",
    "                       that is the style-transfered network\n",
    "    :param style: The network of the style image\n",
    "    :return: The loss between the combination and the style\n",
    "    '''\n",
    "    style_sum = 0.0\n",
    "    for i, l in enumerate(STYLE_LAYERS):\n",
    "        shape = combination[l[0]].get_shape()\n",
    "        M = shape[1].value * shape[2].value\n",
    "        N = shape[3].value\n",
    "        para1 = combination[l[0]]\n",
    "        para2 = style[l[0]]\n",
    "\n",
    "        sub = gram_matrix(para1, M, N) - gram_matrix(para2, M, N)\n",
    "        sum = tf.reduce_sum(tf.pow(sub, 2))\n",
    "        pre = l[1] * 1.0 / (4 * N ** 2 * M ** 2)\n",
    "\n",
    "        style_sum += tf.multiply(pre, sum)\n",
    "\n",
    "    return style_sum\n",
    "    pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define a placeholder\n",
    "    myinput = tf.placeholder(dtype=tf.float32, shape=[1, IMAGE_H, IMAGE_W, 3])\n",
    "\n",
    "    # Read the style image\n",
    "    raw_styleimg = cv2.imread(STYLE_IMG)\n",
    "    raw_styleimg = cv2.resize(raw_styleimg, (IMAGE_H, IMAGE_W))\n",
    "\n",
    "    styleimg = np.expand_dims(raw_styleimg, 0)\n",
    "\n",
    "    # The normalization method of th style image.\n",
    "    # Actually, I have tried many methods, and this one is the most useful and powerful.\n",
    "    styleimg[0][0] -= 123\n",
    "    styleimg[0][1] -= 117\n",
    "    styleimg[0][2] -= 104\n",
    "    styleimg = tf.Variable(styleimg, dtype=tf.float32, trainable=False)\n",
    "\n",
    "    raw_contentimg = cv2.imread(CONTENT_IMG)\n",
    "\n",
    "    # Store the ratio of the content image.\n",
    "    Ratio = raw_contentimg.shape\n",
    "    raw_contentimg = cv2.resize(raw_contentimg, (IMAGE_H, IMAGE_W))\n",
    "\n",
    "    contentimg = np.expand_dims(raw_contentimg, 0)\n",
    "    contentimg[0][0] -= 123\n",
    "    contentimg[0][1] -= 117\n",
    "    contentimg[0][2] -= 104\n",
    "    contentimg = tf.Variable(contentimg, dtype=tf.float32, trainable=False)\n",
    "\n",
    "    # The combination image, which is consisted of noise image and content image.\n",
    "    combination = INI_NOISE_RATIO*np.random.uniform(-20, 20, (1, IMAGE_H, IMAGE_W, 3)).astype('float32') \\\n",
    "                  + \\\n",
    "                  (1.-INI_NOISE_RATIO) * contentimg\n",
    "\n",
    "    combination = tf.Variable(combination, dtype=tf.float32, trainable=True)\n",
    "\n",
    "    # Build all the networks\n",
    "    stylenet = vgg19(myinput * styleimg)\n",
    "\n",
    "    contentnet = vgg19(myinput * contentimg)\n",
    "\n",
    "    combinationnet = vgg19(myinput * combination)\n",
    "\n",
    "    # Define the loss function\n",
    "    loss = 500 * build_style_loss(combinationnet, stylenet) + build_content_loss(combinationnet, contentnet)\n",
    "\n",
    "    # Here, AdamOptimizer is used, and the learning rate is 2.0\n",
    "    train = tf.train.AdamOptimizer(2).minimize(loss)\n",
    "\n",
    "    # Input Image, consisted of 1s.\n",
    "    img = np.ones(dtype=np.float32, shape=[1, IMAGE_H, IMAGE_W, 3])\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for i in range(ITERATION):\n",
    "            print(sess.run(loss, feed_dict={myinput: img}))\n",
    "            sess.run(train, feed_dict={myinput: img})\n",
    "\n",
    "            # Actually, the COMBINATION is the final output.\n",
    "            pic = sess.run(combination, feed_dict={myinput: img})[0]\n",
    "            pic[0] += 123\n",
    "            pic[1] += 117\n",
    "            pic[2] += 104\n",
    "            cv2.imwrite('results/%d.jpg' % i, cv2.resize(pic, (Ratio[1], Ratio[0])))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
